{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaHo93mzKINjdMYWiSaXBF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbehargithub/LinkedIn_Salary/blob/main/Profile_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install playwright\n",
        "!playwright install\n"
      ],
      "metadata": {
        "id": "EEQyMLpja1MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter url, email and password\n",
        "user_url = \"https://www.linkedin.com/in/daniel-behar-168647280\"\n",
        "email = \"daniel10behar@gmail.com\"\n",
        "password = \"alivaba1\"\n"
      ],
      "metadata": {
        "id": "6CBji7t4eWH9"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "import asyncio\n",
        "\n",
        "async def scrape_user_profile(user_url, email, password):\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True)  # Running in headless mode\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        print(\"Navigating to LinkedIn login page...\")\n",
        "        # Navigate to LinkedIn login page\n",
        "        await page.goto(\"https://www.linkedin.com/login\")\n",
        "        await asyncio.sleep(3)\n",
        "\n",
        "        # Perform login\n",
        "        print(\"Logging into LinkedIn...\")\n",
        "        await page.fill('input[id=\"username\"]', email)\n",
        "        await page.fill('input[id=\"password\"]', password)\n",
        "        await page.click('button[type=\"submit\"]')\n",
        "        await asyncio.sleep(5)\n",
        "\n",
        "        # Check for two-step verification\n",
        "        if await page.is_visible('input[name=\"pin\"]'):\n",
        "            print(\"Two-step verification detected. Please enter the code sent to your email.\")\n",
        "            verification_code = input(\"Enter the verification code: \")\n",
        "            await page.fill('input[name=\"pin\"]', verification_code)\n",
        "            await page.click('button[type=\"submit\"]')\n",
        "            await asyncio.sleep(3)\n",
        "\n",
        "        # Relevant sections to scrape for the user\n",
        "        profile_sections = [\n",
        "            \"/details/education/\",\n",
        "            \"/details/skills/\",\n",
        "            \"/details/experience/\",\n",
        "            # \"/details/certifications/\"\n",
        "        ]\n",
        "\n",
        "        scraped_data = {}  # Dictionary to store HTML content of each section\n",
        "\n",
        "        # Loop through the list of profile URLs\n",
        "        for section in profile_sections:\n",
        "            url = f\"{user_url}{section}\"\n",
        "            try:\n",
        "                print(f\"Navigating to section: {url}\")\n",
        "                # Navigate to the section URL\n",
        "                await page.goto(url)\n",
        "                await asyncio.sleep(3)\n",
        "\n",
        "                # Save the HTML content of the section page\n",
        "                html = await page.content()\n",
        "                section_name = section.strip(\"/\").split(\"/\")[-1]  # Keep only the part after the last slash\n",
        "                scraped_data[section_name] = html  # Store HTML content in dictionary\n",
        "                print(f\"HTML content for {section_name} saved in memory.\")\n",
        "\n",
        "                # For debug\n",
        "                filename = f\"{section_name}.html\"  # Ensure .html extension\n",
        "                with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(html)\n",
        "                print(f\"Saved HTML for {url} as {section_name}\")\n",
        "\n",
        "                # Optional: Take a screenshot of the section page\n",
        "                screenshot_filename = f\"{section_name}.png\"\n",
        "                await page.screenshot(path=screenshot_filename, full_page=True)\n",
        "                print(f\"Saved screenshot for {url} as {screenshot_filename}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to scrape {url}: {e}\")\n",
        "\n",
        "        # Close the browser\n",
        "        print(\"Closing the browser...\")\n",
        "        await browser.close()\n",
        "\n",
        "        return scraped_data  # Return all scraped HTML as a dictionary\n",
        "\n"
      ],
      "metadata": {
        "id": "DNftkb7QUFCh"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_html_data = await scrape_user_profile(user_url, email, password)\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Example HTML from the dictionary\n",
        "html_skills = scraped_html_data.get(\"skills\")\n",
        "html_education = scraped_html_data.get(\"education\")\n",
        "html_experience = scraped_html_data.get(\"experience\")\n",
        "\n",
        "# Parse HTML\n",
        "soup_skill = BeautifulSoup(html_skills, \"html.parser\")\n",
        "soup_education = BeautifulSoup(html_education, \"html.parser\")\n",
        "soup_experience = BeautifulSoup(html_experience, \"html.parser\")\n"
      ],
      "metadata": {
        "id": "glxbVQpiZTxn",
        "outputId": "08abe226-d2ab-4ff4-e6f2-5262b99568ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Navigating to LinkedIn login page...\n",
            "Logging into LinkedIn...\n",
            "Navigating to section: https://www.linkedin.com/in/daniel-behar-168647280/details/education/\n",
            "HTML content for education saved in memory.\n",
            "Saved HTML for https://www.linkedin.com/in/daniel-behar-168647280/details/education/ as education\n",
            "Saved screenshot for https://www.linkedin.com/in/daniel-behar-168647280/details/education/ as education.png\n",
            "Navigating to section: https://www.linkedin.com/in/daniel-behar-168647280/details/skills/\n",
            "HTML content for skills saved in memory.\n",
            "Saved HTML for https://www.linkedin.com/in/daniel-behar-168647280/details/skills/ as skills\n",
            "Saved screenshot for https://www.linkedin.com/in/daniel-behar-168647280/details/skills/ as skills.png\n",
            "Navigating to section: https://www.linkedin.com/in/daniel-behar-168647280/details/experience/\n",
            "HTML content for experience saved in memory.\n",
            "Saved HTML for https://www.linkedin.com/in/daniel-behar-168647280/details/experience/ as experience\n",
            "Saved screenshot for https://www.linkedin.com/in/daniel-behar-168647280/details/experience/ as experience.png\n",
            "Closing the browser...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "company_name_container = soup_experience.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\")\n",
        "company_name = (\n",
        "    company_name_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "    if company_name_container else \"N/A\"\n",
        ")\n",
        "\n",
        "duration_container = soup_experience.find(\"span\", class_=\"t-14 t-normal\")\n",
        "if duration_container:\n",
        "    duration_text = duration_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "    if \"·\" in duration_text:\n",
        "        job_type, job_duration = [part.strip() for part in duration_text.split(\"·\", 1)]\n",
        "    else:\n",
        "        job_type, job_duration = \"N/A\", duration_text\n",
        "else:\n",
        "    job_type, job_duration = \"N/A\", \"N/A\"\n",
        "\n",
        "# הצגת התוצאות\n",
        "print(f\"Company Name: {company_name}\")\n",
        "print(f\"Job Duration: {job_duration}\")\n",
        "print(f\"job Type: {job_type}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCIbNhQJbYJN",
        "outputId": "a0bbc8d2-f51a-4e94-d03d-55f46b2cf1b1"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company Name: Israel Defense Forces\n",
            "Job Duration: 4 yrs\n",
            "job Type: N/A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "education_section = soup_education.find(\"main\", {\"aria-label\": \"Education\"})\n",
        "\n",
        "education_records = education_section.find_all(\"div\", {\"data-view-name\": \"profile-component-entity\"})\n",
        "\n",
        "\n",
        "for record in education_records:\n",
        "    print(\"Education record:\")\n",
        "\n",
        "    # Institution name\n",
        "    institution_container = record.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\")\n",
        "    institution_name = institution_container.get_text(strip=True) if institution_container else \"N/A\"\n",
        "    print(f\"  Institution: {institution_name}\")\n",
        "\n",
        "    # Date range\n",
        "    date_container = record.find(\"span\", class_=\"pvs-entity__caption-wrapper\")\n",
        "    date_range = date_container.get_text(strip=True) if date_container else \"N/A\"\n",
        "    print(f\"  Date: {date_range}\")\n",
        "\n",
        "    # Additional description\n",
        "    description_container = record.find(\"span\", class_=\"t-14 t-normal\")\n",
        "    description_text = description_container.get_text(strip=True) if description_container else \"N/A\"\n",
        "    print(f\"  Description: {description_text}\")\n",
        "\n",
        "    # Skills\n",
        "    skills_container = record.find(\"div\", class_=\"display-flex align-items-center t-14 t-normal t-black\")\n",
        "    skills = []\n",
        "    if skills_container:\n",
        "        skills_span = skills_container.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "        if skills_span:\n",
        "            skills_text = skills_span.get_text(strip=True)\n",
        "            if \"Skills:\" in skills_text:\n",
        "                skills_text = skills_text.replace(\"Skills:\", \"\").strip()\n",
        "            skills = [skill.strip() for skill in skills_text.split(\"·\")]\n",
        "    print(f\"  Skills: {', '.join(skills)}\")\n",
        "\n",
        "    # Additional text\n",
        "    additional_text_container = record.find(\"div\", class_=\"inline-show-more-text--is-collapsed\")\n",
        "    additional_text = \"\"\n",
        "    if additional_text_container:\n",
        "        additional_span = additional_text_container.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "        if additional_span:\n",
        "            additional_text = additional_span.get_text(\" \", strip=True)\n",
        "    print(f\"  Additional Text: {additional_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf284XOoSqCq",
        "outputId": "f762addd-f1d7-4f49-81bf-e335c6ca0ac3"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Education record:\n",
            "  Institution: Technion - Israel Institute of TechnologyTechnion - Israel Institute of Technology\n",
            "  Date: Oct 2020\n",
            "  Description: N/A\n",
            "  Skills: Statistical Data Analysis, Apache Spark, Java, Data Structures, PyTorch, Deep Learning, Django\n",
            "  Additional Text: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all <a> tags with data-field=\"skill_page_skill_topic\"\n",
        "skill_links = soup_skill.find_all(\"a\", {\"data-field\": \"skill_page_skill_topic\"})\n",
        "\n",
        "# Extract skills\n",
        "skills = []\n",
        "for link in skill_links:\n",
        "    # Find the <span> with aria-hidden=\"true\" inside the link\n",
        "    skill_span = link.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "    if skill_span:\n",
        "        skill_text = skill_span.get_text(strip=True)\n",
        "        skills.append(skill_text)\n",
        "\n",
        "unique_skills = sorted(set(skills))\n",
        "print(\"Unique skills:\", unique_skills)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLPVQEfBZ-gW",
        "outputId": "ed94eef0-63dc-451d-b474-0fced2063f5c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique skills: ['Apache Spark', 'Data Analysis', 'Data Structures', 'Deep Learning', 'Django', 'HTML', 'Java', 'PyTorch', 'Python (Programming Language)', 'SQL', 'Statistical Data Analysis']\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiGzJ9+RSEGuYRRhYPKNxL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbehargithub/LinkedIn_Salary/blob/main/Profile_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install playwright\n",
        "!playwright install\n"
      ],
      "metadata": {
        "id": "EEQyMLpja1MB",
        "outputId": "2a077751-3535-469c-9b52-9c897a80295d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting playwright\n",
            "  Downloading playwright-1.49.1-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: greenlet==3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright) (3.1.1)\n",
            "Collecting pyee==12.0.0 (from playwright)\n",
            "  Downloading pyee-12.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee==12.0.0->playwright) (4.12.2)\n",
            "Downloading playwright-1.49.1-py3-none-manylinux1_x86_64.whl (44.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-12.0.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pyee, playwright\n",
            "Successfully installed playwright-1.49.1 pyee-12.0.0\n",
            "Downloading Chromium 131.0.6778.33 (playwright build v1148)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1148/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G161.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G161.3 MiB [] 0% 33.2s\u001b[0K\u001b[1G161.3 MiB [] 0% 17.4s\u001b[0K\u001b[1G161.3 MiB [] 0% 11.5s\u001b[0K\u001b[1G161.3 MiB [] 1% 5.7s\u001b[0K\u001b[1G161.3 MiB [] 1% 4.4s\u001b[0K\u001b[1G161.3 MiB [] 2% 3.7s\u001b[0K\u001b[1G161.3 MiB [] 3% 3.2s\u001b[0K\u001b[1G161.3 MiB [] 4% 2.8s\u001b[0K\u001b[1G161.3 MiB [] 5% 2.6s\u001b[0K\u001b[1G161.3 MiB [] 6% 2.4s\u001b[0K\u001b[1G161.3 MiB [] 6% 2.6s\u001b[0K\u001b[1G161.3 MiB [] 7% 2.5s\u001b[0K\u001b[1G161.3 MiB [] 8% 2.4s\u001b[0K\u001b[1G161.3 MiB [] 9% 2.3s\u001b[0K\u001b[1G161.3 MiB [] 10% 2.2s\u001b[0K\u001b[1G161.3 MiB [] 11% 2.1s\u001b[0K\u001b[1G161.3 MiB [] 12% 2.0s\u001b[0K\u001b[1G161.3 MiB [] 14% 1.9s\u001b[0K\u001b[1G161.3 MiB [] 15% 1.9s\u001b[0K\u001b[1G161.3 MiB [] 16% 1.9s\u001b[0K\u001b[1G161.3 MiB [] 17% 1.8s\u001b[0K\u001b[1G161.3 MiB [] 18% 1.8s\u001b[0K\u001b[1G161.3 MiB [] 19% 1.7s\u001b[0K\u001b[1G161.3 MiB [] 20% 1.6s\u001b[0K\u001b[1G161.3 MiB [] 21% 1.6s\u001b[0K\u001b[1G161.3 MiB [] 22% 1.5s\u001b[0K\u001b[1G161.3 MiB [] 23% 1.5s\u001b[0K\u001b[1G161.3 MiB [] 24% 1.5s\u001b[0K\u001b[1G161.3 MiB [] 26% 1.4s\u001b[0K\u001b[1G161.3 MiB [] 27% 1.4s\u001b[0K\u001b[1G161.3 MiB [] 29% 1.3s\u001b[0K\u001b[1G161.3 MiB [] 30% 1.3s\u001b[0K\u001b[1G161.3 MiB [] 31% 1.3s\u001b[0K\u001b[1G161.3 MiB [] 33% 1.2s\u001b[0K\u001b[1G161.3 MiB [] 35% 1.2s\u001b[0K\u001b[1G161.3 MiB [] 36% 1.1s\u001b[0K\u001b[1G161.3 MiB [] 38% 1.1s\u001b[0K\u001b[1G161.3 MiB [] 39% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 41% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 42% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 44% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 45% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 46% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 48% 0.8s\u001b[0K\u001b[1G161.3 MiB [] 49% 0.8s\u001b[0K\u001b[1G161.3 MiB [] 50% 0.8s\u001b[0K\u001b[1G161.3 MiB [] 51% 0.8s\u001b[0K\u001b[1G161.3 MiB [] 53% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 54% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 56% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 58% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 59% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 60% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 62% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 64% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 65% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 66% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 67% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 68% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 70% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 70% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 71% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 72% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 73% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 74% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 75% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 76% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 77% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 78% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 78% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 79% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 80% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 81% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 82% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 83% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 84% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 85% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 85% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 86% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 87% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 88% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 89% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 90% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 91% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 92% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 93% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 94% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 95% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 96% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 97% 0.0s\u001b[0K\u001b[1G161.3 MiB [] 98% 0.0s\u001b[0K\u001b[1G161.3 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 131.0.6778.33 (playwright build v1148) downloaded to /root/.cache/ms-playwright/chromium-1148\n",
            "Downloading Chromium Headless Shell 131.0.6778.33 (playwright build v1148)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1148/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G100.9 MiB [] 0% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 0% 20.8s\u001b[0K\u001b[1G100.9 MiB [] 0% 14.8s\u001b[0K\u001b[1G100.9 MiB [] 0% 10.2s\u001b[0K\u001b[1G100.9 MiB [] 1% 5.1s\u001b[0K\u001b[1G100.9 MiB [] 2% 3.2s\u001b[0K\u001b[1G100.9 MiB [] 3% 2.5s\u001b[0K\u001b[1G100.9 MiB [] 5% 2.1s\u001b[0K\u001b[1G100.9 MiB [] 6% 1.8s\u001b[0K\u001b[1G100.9 MiB [] 8% 1.5s\u001b[0K\u001b[1G100.9 MiB [] 10% 1.4s\u001b[0K\u001b[1G100.9 MiB [] 10% 1.5s\u001b[0K\u001b[1G100.9 MiB [] 11% 1.5s\u001b[0K\u001b[1G100.9 MiB [] 12% 1.5s\u001b[0K\u001b[1G100.9 MiB [] 14% 1.4s\u001b[0K\u001b[1G100.9 MiB [] 15% 1.4s\u001b[0K\u001b[1G100.9 MiB [] 17% 1.3s\u001b[0K\u001b[1G100.9 MiB [] 19% 1.3s\u001b[0K\u001b[1G100.9 MiB [] 21% 1.2s\u001b[0K\u001b[1G100.9 MiB [] 23% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 25% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 26% 1.0s\u001b[0K\u001b[1G100.9 MiB [] 28% 1.0s\u001b[0K\u001b[1G100.9 MiB [] 30% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 31% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 34% 0.8s\u001b[0K\u001b[1G100.9 MiB [] 36% 0.8s\u001b[0K\u001b[1G100.9 MiB [] 38% 0.8s\u001b[0K\u001b[1G100.9 MiB [] 39% 0.7s\u001b[0K\u001b[1G100.9 MiB [] 40% 0.7s\u001b[0K\u001b[1G100.9 MiB [] 42% 0.7s\u001b[0K\u001b[1G100.9 MiB [] 45% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 46% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 48% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 50% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 52% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 54% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 55% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 56% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 58% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 60% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 62% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 63% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 66% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 68% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 70% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 72% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 75% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 77% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 79% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 81% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 84% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 86% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 87% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 89% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 90% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 92% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 94% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 96% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 97% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 98% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 131.0.6778.33 (playwright build v1148) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1148\n",
            "Downloading Firefox 132.0 (playwright build v1466)\u001b[2m from https://playwright.azureedge.net/builds/firefox/1466/firefox-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G87.6 MiB [] 0% 0.0s\u001b[0K\u001b[1G87.6 MiB [] 0% 15.9s\u001b[0K\u001b[1G87.6 MiB [] 0% 12.3s\u001b[0K\u001b[1G87.6 MiB [] 0% 6.1s\u001b[0K\u001b[1G87.6 MiB [] 1% 3.4s\u001b[0K\u001b[1G87.6 MiB [] 3% 2.3s\u001b[0K\u001b[1G87.6 MiB [] 4% 2.0s\u001b[0K\u001b[1G87.6 MiB [] 6% 1.6s\u001b[0K\u001b[1G87.6 MiB [] 7% 1.5s\u001b[0K\u001b[1G87.6 MiB [] 9% 1.3s\u001b[0K\u001b[1G87.6 MiB [] 11% 1.2s\u001b[0K\u001b[1G87.6 MiB [] 12% 1.3s\u001b[0K\u001b[1G87.6 MiB [] 13% 1.2s\u001b[0K\u001b[1G87.6 MiB [] 15% 1.2s\u001b[0K\u001b[1G87.6 MiB [] 16% 1.1s\u001b[0K\u001b[1G87.6 MiB [] 18% 1.1s\u001b[0K\u001b[1G87.6 MiB [] 20% 1.1s\u001b[0K\u001b[1G87.6 MiB [] 21% 1.0s\u001b[0K\u001b[1G87.6 MiB [] 23% 1.0s\u001b[0K\u001b[1G87.6 MiB [] 26% 0.9s\u001b[0K\u001b[1G87.6 MiB [] 28% 0.8s\u001b[0K\u001b[1G87.6 MiB [] 31% 0.8s\u001b[0K\u001b[1G87.6 MiB [] 33% 0.8s\u001b[0K\u001b[1G87.6 MiB [] 35% 0.7s\u001b[0K\u001b[1G87.6 MiB [] 38% 0.7s\u001b[0K\u001b[1G87.6 MiB [] 41% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 42% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 44% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 46% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 49% 0.5s\u001b[0K\u001b[1G87.6 MiB [] 51% 0.5s\u001b[0K\u001b[1G87.6 MiB [] 53% 0.5s\u001b[0K\u001b[1G87.6 MiB [] 56% 0.4s\u001b[0K\u001b[1G87.6 MiB [] 59% 0.4s\u001b[0K\u001b[1G87.6 MiB [] 62% 0.3s\u001b[0K\u001b[1G87.6 MiB [] 65% 0.3s\u001b[0K\u001b[1G87.6 MiB [] 68% 0.3s\u001b[0K\u001b[1G87.6 MiB [] 70% 0.3s\u001b[0K\u001b[1G87.6 MiB [] 72% 0.2s\u001b[0K\u001b[1G87.6 MiB [] 75% 0.2s\u001b[0K\u001b[1G87.6 MiB [] 78% 0.2s\u001b[0K\u001b[1G87.6 MiB [] 81% 0.2s\u001b[0K\u001b[1G87.6 MiB [] 84% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 85% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 88% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 90% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 92% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 94% 0.0s\u001b[0K\u001b[1G87.6 MiB [] 97% 0.0s\u001b[0K\u001b[1G87.6 MiB [] 100% 0.0s\u001b[0K\n",
            "Firefox 132.0 (playwright build v1466) downloaded to /root/.cache/ms-playwright/firefox-1466\n",
            "Downloading Webkit 18.2 (playwright build v2104)\u001b[2m from https://playwright.azureedge.net/builds/webkit/2104/webkit-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G95.5 MiB [] 0% 0.0s\u001b[0K\u001b[1G95.5 MiB [] 0% 19.7s\u001b[0K\u001b[1G95.5 MiB [] 0% 11.9s\u001b[0K\u001b[1G95.5 MiB [] 0% 10.2s\u001b[0K\u001b[1G95.5 MiB [] 1% 5.2s\u001b[0K\u001b[1G95.5 MiB [] 2% 3.6s\u001b[0K\u001b[1G95.5 MiB [] 3% 2.9s\u001b[0K\u001b[1G95.5 MiB [] 4% 2.6s\u001b[0K\u001b[1G95.5 MiB [] 5% 2.5s\u001b[0K\u001b[1G95.5 MiB [] 6% 2.8s\u001b[0K\u001b[1G95.5 MiB [] 6% 3.0s\u001b[0K\u001b[1G95.5 MiB [] 8% 2.5s\u001b[0K\u001b[1G95.5 MiB [] 9% 2.4s\u001b[0K\u001b[1G95.5 MiB [] 10% 2.3s\u001b[0K\u001b[1G95.5 MiB [] 11% 2.2s\u001b[0K\u001b[1G95.5 MiB [] 11% 2.3s\u001b[0K\u001b[1G95.5 MiB [] 12% 2.3s\u001b[0K\u001b[1G95.5 MiB [] 13% 2.3s\u001b[0K\u001b[1G95.5 MiB [] 14% 2.2s\u001b[0K\u001b[1G95.5 MiB [] 15% 2.0s\u001b[0K\u001b[1G95.5 MiB [] 16% 2.0s\u001b[0K\u001b[1G95.5 MiB [] 17% 1.9s\u001b[0K\u001b[1G95.5 MiB [] 18% 1.9s\u001b[0K\u001b[1G95.5 MiB [] 19% 1.8s\u001b[0K\u001b[1G95.5 MiB [] 20% 1.7s\u001b[0K\u001b[1G95.5 MiB [] 22% 1.7s\u001b[0K\u001b[1G95.5 MiB [] 23% 1.6s\u001b[0K\u001b[1G95.5 MiB [] 24% 1.6s\u001b[0K\u001b[1G95.5 MiB [] 26% 1.5s\u001b[0K\u001b[1G95.5 MiB [] 27% 1.5s\u001b[0K\u001b[1G95.5 MiB [] 28% 1.4s\u001b[0K\u001b[1G95.5 MiB [] 30% 1.3s\u001b[0K\u001b[1G95.5 MiB [] 31% 1.3s\u001b[0K\u001b[1G95.5 MiB [] 33% 1.2s\u001b[0K\u001b[1G95.5 MiB [] 35% 1.2s\u001b[0K\u001b[1G95.5 MiB [] 37% 1.1s\u001b[0K\u001b[1G95.5 MiB [] 38% 1.1s\u001b[0K\u001b[1G95.5 MiB [] 39% 1.1s\u001b[0K\u001b[1G95.5 MiB [] 40% 1.1s\u001b[0K\u001b[1G95.5 MiB [] 41% 1.0s\u001b[0K\u001b[1G95.5 MiB [] 42% 1.0s\u001b[0K\u001b[1G95.5 MiB [] 44% 0.9s\u001b[0K\u001b[1G95.5 MiB [] 46% 0.9s\u001b[0K\u001b[1G95.5 MiB [] 48% 0.8s\u001b[0K\u001b[1G95.5 MiB [] 49% 0.8s\u001b[0K\u001b[1G95.5 MiB [] 51% 0.8s\u001b[0K\u001b[1G95.5 MiB [] 53% 0.7s\u001b[0K\u001b[1G95.5 MiB [] 55% 0.7s\u001b[0K\u001b[1G95.5 MiB [] 56% 0.7s\u001b[0K\u001b[1G95.5 MiB [] 58% 0.6s\u001b[0K\u001b[1G95.5 MiB [] 60% 0.6s\u001b[0K\u001b[1G95.5 MiB [] 62% 0.6s\u001b[0K\u001b[1G95.5 MiB [] 63% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 64% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 65% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 66% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 67% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 69% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 71% 0.4s\u001b[0K\u001b[1G95.5 MiB [] 73% 0.4s\u001b[0K\u001b[1G95.5 MiB [] 74% 0.4s\u001b[0K\u001b[1G95.5 MiB [] 76% 0.3s\u001b[0K\u001b[1G95.5 MiB [] 77% 0.3s\u001b[0K\u001b[1G95.5 MiB [] 78% 0.3s\u001b[0K\u001b[1G95.5 MiB [] 80% 0.3s\u001b[0K\u001b[1G95.5 MiB [] 82% 0.2s\u001b[0K\u001b[1G95.5 MiB [] 83% 0.2s\u001b[0K\u001b[1G95.5 MiB [] 85% 0.2s\u001b[0K\u001b[1G95.5 MiB [] 87% 0.2s\u001b[0K\u001b[1G95.5 MiB [] 89% 0.1s\u001b[0K\u001b[1G95.5 MiB [] 91% 0.1s\u001b[0K\u001b[1G95.5 MiB [] 92% 0.1s\u001b[0K\u001b[1G95.5 MiB [] 94% 0.1s\u001b[0K\u001b[1G95.5 MiB [] 95% 0.1s\u001b[0K\u001b[1G95.5 MiB [] 97% 0.0s\u001b[0K\u001b[1G95.5 MiB [] 98% 0.0s\u001b[0K\u001b[1G95.5 MiB [] 99% 0.0s\u001b[0K\u001b[1G95.5 MiB [] 100% 0.0s\u001b[0K\n",
            "Webkit 18.2 (playwright build v2104) downloaded to /root/.cache/ms-playwright/webkit-2104\n",
            "Downloading FFMPEG playwright build v1010\u001b[2m from https://playwright.azureedge.net/builds/ffmpeg/1010/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 3% 0.5s\u001b[0K\u001b[1G2.3 MiB [] 10% 0.3s\u001b[0K\u001b[1G2.3 MiB [] 33% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 77% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1010 downloaded to /root/.cache/ms-playwright/ffmpeg-1010\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libavif.so.13                                    ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\u001b[39m\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:753:43)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:851:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:840:43)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/cli/program.js:137:7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter url, email and password\n",
        "user_url = \"https://www.linkedin.com/in/daniel-behar-168647280\"\n",
        "email = \"daniel10behar@gmail.com\"\n",
        "password = \"alivaba1\"\n"
      ],
      "metadata": {
        "id": "6CBji7t4eWH9"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "import asyncio\n",
        "\n",
        "async def scrape_user_profile(user_url, email, password):\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True)  # Running in headless mode\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        print(\"Navigating to LinkedIn login page...\")\n",
        "        # Navigate to LinkedIn login page\n",
        "        await page.goto(\"https://www.linkedin.com/login\")\n",
        "        await asyncio.sleep(3)\n",
        "\n",
        "        # Perform login\n",
        "        print(\"Logging into LinkedIn...\")\n",
        "        await page.fill('input[id=\"username\"]', email)\n",
        "        await page.fill('input[id=\"password\"]', password)\n",
        "        await page.click('button[type=\"submit\"]')\n",
        "        await asyncio.sleep(5)\n",
        "\n",
        "        # Check for two-step verification\n",
        "        if await page.is_visible('input[name=\"pin\"]'):\n",
        "            print(\"Two-step verification detected. Please enter the code sent to your email.\")\n",
        "            verification_code = input(\"Enter the verification code: \")\n",
        "            await page.fill('input[name=\"pin\"]', verification_code)\n",
        "            await page.click('button[type=\"submit\"]')\n",
        "            await asyncio.sleep(3)\n",
        "\n",
        "        # Relevant sections to scrape for the user\n",
        "        profile_sections = [\n",
        "            \"/details/education/\",\n",
        "            \"/details/skills/\",\n",
        "            \"/details/experience/\",\n",
        "            # \"/details/certifications/\"\n",
        "        ]\n",
        "\n",
        "        scraped_data = {}  # Dictionary to store HTML content of each section\n",
        "\n",
        "        # מספר ניסיונות להורדת HTML\n",
        "        MAX_RETRIES = 3\n",
        "\n",
        "        # Loop through the list of profile URLs\n",
        "        for section in profile_sections:\n",
        "            url = f\"{user_url}{section}\"\n",
        "            retries = 0\n",
        "\n",
        "            while retries < MAX_RETRIES:\n",
        "                try:\n",
        "                    print(f\"Navigating to section: {url} (Attempt {retries + 1})\")\n",
        "\n",
        "                    # Navigate to the section URL\n",
        "                    await page.goto(url)\n",
        "                    await asyncio.sleep(3)\n",
        "\n",
        "                    # Get page title to verify if the correct page is loaded\n",
        "                    page_title = await page.title()\n",
        "                    section_name = section.strip(\"/\").split(\"/\")[-1]  # Extract section name\n",
        "                    print(f\"Page title: {page_title}\")\n",
        "                    print(f\"Section name: {section_name}\")\n",
        "\n",
        "                    # Verify if the page is correct\n",
        "                    if section_name.capitalize() not in page_title:\n",
        "                        print(f\"Page {url} did not load correctly. Retrying...\")\n",
        "                        retries += 1\n",
        "                        await asyncio.sleep(5)  # Wait a bit before retrying\n",
        "                        continue  # Retry the same section\n",
        "\n",
        "                    # Save the HTML content of the section page\n",
        "                    html = await page.content()\n",
        "                    scraped_data[section_name] = html  # Store HTML content in dictionary\n",
        "                    print(f\"HTML content for {section_name} saved in memory.\")\n",
        "\n",
        "                    # Save the HTML file for debugging\n",
        "                    filename = f\"{section_name}.html\"\n",
        "                    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(html)\n",
        "                    print(f\"Saved HTML for {url} as {section_name}\")\n",
        "\n",
        "                    # Take a screenshot of the section page\n",
        "                    screenshot_filename = f\"{section_name}.png\"\n",
        "                    await page.screenshot(path=screenshot_filename, full_page=True)\n",
        "                    print(f\"Saved screenshot for {url} as {screenshot_filename}\")\n",
        "\n",
        "                    break  # If successful, exit the retry loop\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to scrape {url}: {e}\")\n",
        "                    retries += 1\n",
        "                    await asyncio.sleep(5)  # Wait a bit before retrying\n",
        "\n",
        "            if retries == MAX_RETRIES:\n",
        "                print(f\"Failed to scrape {url} after {MAX_RETRIES} attempts. Skipping...\")\n",
        "\n",
        "        # Close the browser\n",
        "        print(\"Closing the browser...\")\n",
        "        await browser.close()\n",
        "\n",
        "        return scraped_data  # Return all scraped HTML as a dictionary\n",
        "\n"
      ],
      "metadata": {
        "id": "DNftkb7QUFCh"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_html_data = await scrape_user_profile(user_url, email, password)\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Example HTML from the dictionary\n",
        "html_skills = scraped_html_data.get(\"skills\")\n",
        "html_education = scraped_html_data.get(\"education\")\n",
        "html_experience = scraped_html_data.get(\"experience\")\n",
        "\n",
        "# Parse HTML\n",
        "soup_skill = BeautifulSoup(html_skills, \"html.parser\")\n",
        "soup_education = BeautifulSoup(html_education, \"html.parser\")\n",
        "soup_experience = BeautifulSoup(html_experience, \"html.parser\")\n"
      ],
      "metadata": {
        "id": "glxbVQpiZTxn",
        "outputId": "6be774e0-2946-4a73-e11c-a94a4e33d1e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Navigating to LinkedIn login page...\n",
            "Logging into LinkedIn...\n",
            "Navigating to section: https://www.linkedin.com/in/daniel-behar-168647280/details/education/ (Attempt 1)\n",
            "Page title: (13) Education | Daniel Behar | LinkedIn\n",
            "Section name: education\n",
            "HTML content for education saved in memory.\n",
            "Saved HTML for https://www.linkedin.com/in/daniel-behar-168647280/details/education/ as education\n",
            "Saved screenshot for https://www.linkedin.com/in/daniel-behar-168647280/details/education/ as education.png\n",
            "Navigating to section: https://www.linkedin.com/in/daniel-behar-168647280/details/skills/ (Attempt 1)\n",
            "Page title: (13) Skills | Daniel Behar | LinkedIn\n",
            "Section name: skills\n",
            "HTML content for skills saved in memory.\n",
            "Saved HTML for https://www.linkedin.com/in/daniel-behar-168647280/details/skills/ as skills\n",
            "Saved screenshot for https://www.linkedin.com/in/daniel-behar-168647280/details/skills/ as skills.png\n",
            "Navigating to section: https://www.linkedin.com/in/daniel-behar-168647280/details/experience/ (Attempt 1)\n",
            "Page title: (13) Experience | Daniel Behar | LinkedIn\n",
            "Section name: experience\n",
            "HTML content for experience saved in memory.\n",
            "Saved HTML for https://www.linkedin.com/in/daniel-behar-168647280/details/experience/ as experience\n",
            "Saved screenshot for https://www.linkedin.com/in/daniel-behar-168647280/details/experience/ as experience.png\n",
            "Closing the browser...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cnBjtRq8vUNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_IKLTQQzvUKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experience_section = soup_experience.find(\"main\", {\"aria-label\": \"Experience\"})\n",
        "\n",
        "company_records = experience_section.find_all(\"li\", class_=\"pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column\")\n",
        "\n",
        "for company in company_records:\n",
        "    # שם החברה\n",
        "    company_name_container = company.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\") or \\\n",
        "                         company.find(\"div\", class_=\"display-flex align-items-center mr1 t-bold\")\n",
        "    company_name = (\n",
        "        company_name_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "        if company_name_container else \"N/A\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # משך העבודה וסוג העבודה\n",
        "    duration_container = company.find(\"span\", class_=\"t-14 t-normal\")\n",
        "    if duration_container:\n",
        "        duration_text = duration_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "        if \"·\" in duration_text:\n",
        "            job_type, job_duration = [part.strip() for part in duration_text.split(\"·\", 1)]\n",
        "        else:\n",
        "            job_type, job_duration = \"N/A\", duration_text\n",
        "    else:\n",
        "        job_type, job_duration = \"N/A\", \"N/A\"\n",
        "\n",
        "\n",
        "    additional_content_container = company.find(\"div\", class_=\"display-flex align-items-center t-14 t-normal t-black\")\n",
        "    additional_content = (\n",
        "        additional_content_container.get_text(strip=True) if additional_content_container else \"N/A\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # הצגת התוצאות\n",
        "    print(f\"Company Name: {company_name}\")\n",
        "    print(f\"Job Duration: {job_duration}\")\n",
        "    print(f\"Job Type: {job_type}\")\n",
        "    print(f\"Additional Content: {additional_content}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "YSd7IInFvUHW",
        "outputId": "355d2805-ab29-4400-864f-6bb19f890687",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company Name: Israel Defense Forces\n",
            "Job Duration: 4 yrs\n",
            "Job Type: N/A\n",
            "Additional Content: N/A\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0cz3qzfEvT_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-PO5Od7AvCqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-d3ekwHZvCoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PXqb5sVFvCln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "education_section = soup_education.find(\"main\", {\"aria-label\": \"Education\"})\n",
        "\n",
        "education_records = education_section.find_all(\"div\", {\"data-view-name\": \"profile-component-entity\"})\n",
        "\n",
        "for record in education_records:\n",
        "    print(\"Education record:\")\n",
        "\n",
        "    # Institution name\n",
        "    institution_container = record.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\")\n",
        "    institution_name = institution_container.get_text(strip=True) if institution_container else \"N/A\"\n",
        "    print(f\"  Institution: {institution_name}\")\n",
        "\n",
        "    # Date range\n",
        "    date_container = record.find(\"span\", class_=\"pvs-entity__caption-wrapper\")\n",
        "    date_range = date_container.get_text(strip=True) if date_container else \"N/A\"\n",
        "    print(f\"  Date: {date_range}\")\n",
        "\n",
        "    # Additional description\n",
        "    description_container = record.find(\"span\", class_=\"t-14 t-normal\")\n",
        "    description_text = description_container.get_text(strip=True) if description_container else \"N/A\"\n",
        "    print(f\"  Description: {description_text}\")\n",
        "\n",
        "    # Skills\n",
        "    skills_container = record.find(\"div\", class_=\"display-flex align-items-center t-14 t-normal t-black\")\n",
        "    skills = []\n",
        "    if skills_container:\n",
        "        skills_span = skills_container.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "        if skills_span:\n",
        "            skills_text = skills_span.get_text(strip=True)\n",
        "            if \"Skills:\" in skills_text:\n",
        "                skills_text = skills_text.replace(\"Skills:\", \"\").strip()\n",
        "            skills = [skill.strip() for skill in skills_text.split(\"·\")]\n",
        "    print(f\"  Skills: {', '.join(skills)}\")\n",
        "\n",
        "    # Additional text\n",
        "    additional_text_container = record.find(\"div\", class_=\"inline-show-more-text--is-collapsed\")\n",
        "    additional_text = \"\"\n",
        "    if additional_text_container:\n",
        "        additional_span = additional_text_container.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "        if additional_span:\n",
        "            additional_text = additional_span.get_text(\" \", strip=True)\n",
        "    print(f\"  Additional Text: {additional_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf284XOoSqCq",
        "outputId": "6e66d374-ff82-4bd0-9b9c-12bd1e191a64"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Education record:\n",
            "  Institution: Technion - Israel Institute of TechnologyTechnion - Israel Institute of Technology\n",
            "  Date: Oct 2020\n",
            "  Description: N/A\n",
            "  Skills: Statistical Data Analysis, Apache Spark, Java, Data Structures, PyTorch, Deep Learning, Django\n",
            "  Additional Text: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all <a> tags with data-field=\"skill_page_skill_topic\"\n",
        "skill_links = soup_skill.find_all(\"a\", {\"data-field\": \"skill_page_skill_topic\"})\n",
        "\n",
        "# Extract skills\n",
        "skills = []\n",
        "for link in skill_links:\n",
        "    # Find the <span> with aria-hidden=\"true\" inside the link\n",
        "    skill_span = link.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "    if skill_span:\n",
        "        skill_text = skill_span.get_text(strip=True)\n",
        "        skills.append(skill_text)\n",
        "\n",
        "unique_skills = sorted(set(skills))\n",
        "print(\"Unique skills:\", unique_skills)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLPVQEfBZ-gW",
        "outputId": "ab0ada62-f3c9-474c-be01-fe16333b2d0e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique skills: ['Apache Spark', 'Data Analysis', 'Data Structures', 'Deep Learning', 'Django', 'HTML', 'Java', 'PyTorch', 'Python (Programming Language)', 'SQL', 'Statistical Data Analysis']\n"
          ]
        }
      ]
    }
  ]
}
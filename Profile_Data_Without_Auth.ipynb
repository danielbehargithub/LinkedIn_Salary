{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx1lB3FL+8JpBMvwseBf6F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbehargithub/LinkedIn_Salary/blob/main/Profile_Data_Without_Auth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please click on Runtime -> Run all.\n",
        "\n",
        "Enter html files and job url.\n",
        "\n",
        "You will recive your LinkedIn and job data.\n",
        "\n",
        "For full guide go to README file."
      ],
      "metadata": {
        "id": "KHKzgRHuz_P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Step 1: Upload Experience HTML\n",
        "print(\"Please upload the Experience HTML file (e.g., experience.html).\")\n",
        "uploaded_experience = files.upload()\n",
        "experience_html = uploaded_experience.get(next(iter(uploaded_experience.keys())))\n",
        "\n",
        "# Step 2: Upload Education HTML\n",
        "print(\"\\nPlease upload the Education HTML file (e.g., education.html).\")\n",
        "uploaded_education = files.upload()\n",
        "education_html = uploaded_education.get(next(iter(uploaded_education.keys())))\n",
        "\n",
        "# Step 3: Upload Skills HTML\n",
        "print(\"\\nPlease upload the Skills HTML file (e.g., skills.html).\")\n",
        "uploaded_skills = files.upload()\n",
        "skills_html = uploaded_skills.get(next(iter(uploaded_skills.keys())))\n",
        "\n",
        "# Validate that all files were uploaded\n",
        "if not experience_html or not education_html or not skills_html:\n",
        "    raise ValueError(\"All required files (Experience, Education, Skills) must be uploaded.\")\n",
        "\n",
        "\n",
        "\n",
        "# Request the URL from the user\n",
        "job_url = input(\"Please enter the LinkedIn job URL: \").strip()\n"
      ],
      "metadata": {
        "id": "P-WFc69VzIMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "from re import sub\n"
      ],
      "metadata": {
        "id": "QsUA4CBFdR9x"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_experience_html(html_experience):\n",
        "    \"\"\"\n",
        "    Process the HTML file for the Experience section.\n",
        "    \"\"\"\n",
        "    soup_experience = BeautifulSoup(html_experience, \"html.parser\")\n",
        "    # Initialize the output variable to collect results\n",
        "    output = \"Experience Section:\\n\\n\"\n",
        "\n",
        "    # Locate the experience section in the HTML using its aria-label\n",
        "    experience_section = soup_experience.find(\"main\", {\"aria-label\": \"Experience\"})\n",
        "\n",
        "    # Find all job records within the experience section\n",
        "    records = experience_section.find_all(\"li\", class_=\"pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column\")\n",
        "\n",
        "    # Process each job record\n",
        "    for record in records:\n",
        "        # Check if the record contains sub-records (multiple roles in one company)\n",
        "        sub_records = record.find_all(\"li\", class_=\"pvs-list__paged-list-item pvs-list__item--one-column\")\n",
        "\n",
        "        # Handle a single position in one company\n",
        "        if len(sub_records) == 0:\n",
        "            # Extract job title\n",
        "            job_name_container = record.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\") or \\\n",
        "                                record.find(\"div\", class_=\"display-flex align-items-center mr1 t-bold\")\n",
        "            job_name = (\n",
        "                job_name_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "                if job_name_container else \"N/A\"\n",
        "            )\n",
        "\n",
        "            # Extract company name and job type\n",
        "            job_place_and_type_container = record.find(\"span\", class_=\"t-14 t-normal\")\n",
        "            if job_place_and_type_container:\n",
        "                place_and_type = job_place_and_type_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "                if \"·\" in place_and_type:\n",
        "                    company_name, job_type = [part.strip() for part in place_and_type.split(\"·\", 1)]\n",
        "                else:\n",
        "                    company_name, job_type = \"N/A\", place_and_type\n",
        "            else:\n",
        "                company_name, job_type = \"N/A\", \"N/A\"\n",
        "\n",
        "            # Extract job duration and location\n",
        "            job_info_container = record.find_all(\"span\", class_=\"t-14 t-normal t-black--light\")\n",
        "            info = [span.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) for span in job_info_container if span.find(\"span\", {\"aria-hidden\": \"true\"})]\n",
        "            job_duration = info[0] if len(info) > 0 else \"N/A\"\n",
        "            job_location = info[1] if len(info) > 1 else \"N/A\"\n",
        "\n",
        "            # Extract additional content and skills\n",
        "            additional_content_container = record.find_all(\"div\", class_=\"display-flex align-items-center t-14 t-normal t-black\")\n",
        "            additional_content_and_skills = [span.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) for span in additional_content_container if span.find(\"span\", {\"aria-hidden\": \"true\"})]\n",
        "            additional_content = additional_content_and_skills[0] if len(additional_content_and_skills) > 0 else \"N/A\"\n",
        "\n",
        "            skills = additional_content_and_skills[1] if len(additional_content_and_skills) > 1 else \"N/A\"\n",
        "            skills = skills.replace(\"Skills:\", \"\").strip()\n",
        "\n",
        "            # Append results to the output in a clean format\n",
        "            output += (\n",
        "                f\"Job Title     : {job_name}\\n\"\n",
        "                f\"Company       : {company_name}\\n\"\n",
        "                f\"Job Type      : {job_type}\\n\"\n",
        "                f\"Job Duration  : {job_duration}\\n\"\n",
        "                f\"Location      : {job_location}\\n\"\n",
        "                f\"Description   : {additional_content}\\n\"\n",
        "                f\"Skills        : {skills}\\n\"\n",
        "                f\"{'-' * 50}\\n\"\n",
        "            )\n",
        "        else:\n",
        "            # Handle multiple roles in the same company\n",
        "            title_container = record.find(\"div\", class_=\"display-flex flex-row justify-space-between\")\n",
        "            company_name_container = title_container.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\") or \\\n",
        "                                    title_container.find(\"div\", class_=\"display-flex align-items-center mr1 t-bold\")\n",
        "            company_name = (\n",
        "                company_name_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "                if company_name_container else \"N/A\"\n",
        "            )\n",
        "            duration_container = title_container.find(\"span\", class_=\"t-14 t-normal\")\n",
        "            duration = duration_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "\n",
        "            # Append company details to the output\n",
        "            output += (\n",
        "                f\"Company       : {company_name}\\n\"\n",
        "                f\"Duration      : {duration}\\n\"\n",
        "                f\"{'-' * 50}\\n\"\n",
        "            )\n",
        "\n",
        "            # Process each sub-record (job role)\n",
        "            for sub_record in sub_records:\n",
        "                # Extract job title\n",
        "                job_name_container = sub_record.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\") or \\\n",
        "                                    sub_record.find(\"div\", class_=\"display-flex align-items-center mr1 t-bold\")\n",
        "                job_name = (\n",
        "                    job_name_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "                    if job_name_container else \"N/A\"\n",
        "                )\n",
        "\n",
        "                # Extract company name and job type\n",
        "                job_place_and_type_container = sub_record.find(\"span\", class_=\"t-14 t-normal\")\n",
        "                if job_place_and_type_container:\n",
        "                    place_and_type = job_place_and_type_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "                    if \"·\" in place_and_type:\n",
        "                        company_name, job_type = [part.strip() for part in place_and_type.split(\"·\", 1)]\n",
        "                    else:\n",
        "                        company_name, job_type = \"N/A\", place_and_type\n",
        "                else:\n",
        "                    company_name, job_type = \"N/A\", \"N/A\"\n",
        "\n",
        "                # Extract job duration and location\n",
        "                job_info_container = sub_record.find_all(\"span\", class_=\"t-14 t-normal t-black--light\")\n",
        "                info = [span.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) for span in job_info_container if span.find(\"span\", {\"aria-hidden\": \"true\"})]\n",
        "                job_duration = info[0] if len(info) > 0 else \"N/A\"\n",
        "                job_location = info[1] if len(info) > 1 else \"N/A\"\n",
        "\n",
        "                # Extract additional content and skills\n",
        "                additional_content_container = sub_record.find_all(\"div\", class_=\"display-flex align-items-center t-14 t-normal t-black\")\n",
        "                if len(additional_content_container) == 1:\n",
        "                  if \"Skills:\" in additional_content_container[0].get_text(strip=True):\n",
        "                    additional_content_and_skills = [span.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) for span in additional_content_container]\n",
        "                    skills = additional_content_and_skills[0]\n",
        "                    skills = skills.replace(\"Skills:\", \"\").strip()\n",
        "                else:\n",
        "\n",
        "                    additional_content_and_skills = [span.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) for span in additional_content_container if span.find(\"span\", {\"aria-hidden\": \"true\"})]\n",
        "                    additional_content = additional_content_and_skills[0] if len(additional_content_and_skills) > 0 else \"N/A\"\n",
        "\n",
        "                    skills = additional_content_and_skills[1] if len(additional_content_and_skills) > 1 else \"N/A\"\n",
        "                    skills = skills.replace(\"Skills:\", \"\").strip()\n",
        "\n",
        "                # Append job role details to the output in a clean format\n",
        "                output += (\n",
        "                    f\"  Job Title    : {job_name}\\n\"\n",
        "                    f\"  Job Type     : {job_type}\\n\"\n",
        "                    f\"  Job Duration : {job_duration}\\n\"\n",
        "                    f\"  Location     : {job_location}\\n\"\n",
        "                    f\"  Description  : {additional_content}\\n\"\n",
        "                    f\"  Skills       : {skills}\\n\"\n",
        "                    f\"  {'-' * 50}\\n\"\n",
        "                )\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "Wdzv9a_idR7V"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_education_html(html_education):\n",
        "    \"\"\"\n",
        "    Process the HTML file for the Education section.\n",
        "    \"\"\"\n",
        "    soup_education = BeautifulSoup(html_education, \"html.parser\")\n",
        "\n",
        "    output = \"Education Section:\\n\\n\"\n",
        "\n",
        "\n",
        "    # Locate the education section in the HTML\n",
        "    education_section = soup_education.find(\"main\", {\"aria-label\": \"Education\"})\n",
        "\n",
        "    # Find all education records within the section\n",
        "    education_records = education_section.find_all(\"div\", {\"data-view-name\": \"profile-component-entity\"})\n",
        "\n",
        "    # Process each education record\n",
        "    for record in education_records:\n",
        "        # Extract institution name\n",
        "        institution_container = record.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\")\n",
        "        institution_name = institution_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) if institution_container else \"N/A\"\n",
        "        output += f\"Institution     : {institution_name}\\n\"\n",
        "\n",
        "        # Extract date range\n",
        "        date_container = record.find(\"span\", class_=\"pvs-entity__caption-wrapper\")\n",
        "        date_range = date_container.get_text(strip=True) if date_container else \"N/A\"\n",
        "        output += f\"Date Range      : {date_range}\\n\"\n",
        "\n",
        "        # Extract additional description (e.g., degree or field of study)\n",
        "        description_container = record.find(\"span\", class_=\"t-14 t-normal\")\n",
        "        description_text = description_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) if description_container else \"N/A\"\n",
        "        output += f\"Description     : {description_text}\\n\"\n",
        "\n",
        "        # Extract skills (if available)\n",
        "        skills_container = record.find(\"div\", class_=\"display-flex align-items-center t-14 t-normal t-black\")\n",
        "        skills = []\n",
        "        if skills_container:\n",
        "            skills_span = skills_container.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "            if skills_span:\n",
        "                skills_text = skills_span.get_text(strip=True)\n",
        "                if \"Skills:\" in skills_text:\n",
        "                    skills_text = skills_text.replace(\"Skills:\", \"\").strip()\n",
        "                skills = [skill.strip() for skill in skills_text.split(\"·\")]\n",
        "        output += f\"Skills          : {', '.join(skills) if skills else 'N/A'}\\n\"\n",
        "\n",
        "        # Extract additional text (e.g., detailed explanations)\n",
        "        additional_text_container = record.find(\"div\", class_=\"inline-show-more-text--is-collapsed\")\n",
        "        additional_text = \"\"\n",
        "        if additional_text_container:\n",
        "            additional_span = additional_text_container.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "            if additional_span:\n",
        "                additional_text = additional_span.get_text(\" \", strip=True)\n",
        "        output += f\"Additional Text : {additional_text if additional_text else 'N/A'}\\n\"\n",
        "\n",
        "        # Append a separator for readability\n",
        "        output += \"-\" * 50 + \"\\n\"\n",
        "\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "Zza3VzrVdR4g"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_skills_html(html_skills):\n",
        "    \"\"\"\n",
        "    Process the HTML file for the Education section.\n",
        "    \"\"\"\n",
        "    soup_skills = BeautifulSoup(html_skills, \"html.parser\")\n",
        "\n",
        "    output = \"Skills Section:\\n\\n\"\n",
        "\n",
        "    # Find all <a> tags with data-field=\"skill_page_skill_topic\"\n",
        "    skill_links = soup_skills.find_all(\"a\", {\"data-field\": \"skill_page_skill_topic\"})\n",
        "\n",
        "    # Extract skills\n",
        "    skills = []\n",
        "    for link in skill_links:\n",
        "        # Find the <span> with aria-hidden=\"true\" inside the link\n",
        "        skill_span = link.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "        if skill_span:\n",
        "            skill_text = skill_span.get_text(strip=True)\n",
        "            skills.append(skill_text)\n",
        "\n",
        "    unique_skills = sorted(set(skills))\n",
        "\n",
        "    output += f\"Unique skills: {', '.join(unique_skills)}\\n\"\n",
        "    output += \"-\" * 50 + \"\\n\"\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "R56gEMCcdR1_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_and_process(section_name, process_function):\n",
        "    \"\"\"\n",
        "    Helper function to upload a file, process it, and append the results to combined_output.\n",
        "    \"\"\"\n",
        "    print(f\"Please upload the {section_name} HTML file:\")\n",
        "    uploaded_files = files.upload()\n",
        "    file_name, content = next(iter(uploaded_files.items()))\n",
        "\n",
        "    print(f\"Processing {section_name} file: {file_name}\\n\")\n",
        "    output = process_function(content)\n",
        "\n",
        "    # Append the section output to the combined output\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "-byMpBIxgMqG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install playwright\n",
        "!playwright install"
      ],
      "metadata": {
        "id": "VdMzZTbIqayx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from playwright.async_api import async_playwright\n",
        "import asyncio\n",
        "\n",
        "async def scrape_job_posting(job_url):\n",
        "    \"\"\"\n",
        "    Scrape job posting details from a LinkedIn job URL and save to a file.\n",
        "    \"\"\"\n",
        "    async with async_playwright() as p:\n",
        "        # Launch browser in headless mode\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        context = await browser.new_context(user_agent=\"Mozilla/5.0\")\n",
        "        page = await context.new_page()\n",
        "\n",
        "        # Navigate to the provided job URL\n",
        "        print(f\"Navigating to {job_url}...\")\n",
        "        await page.goto(job_url)\n",
        "        await asyncio.sleep(5)  # Wait for the page to fully load\n",
        "\n",
        "        # Save the page's HTML content for debugging purposes\n",
        "        # html = await page.content()\n",
        "        # with open(\"page_debug.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "        #     f.write(html)\n",
        "        # print(\"Saved page content to page_debug.html\")\n",
        "\n",
        "        # Take a screenshot of the page for verification\n",
        "        # await page.screenshot(path=\"screenshot.png\", full_page=True)\n",
        "        # print(\"Screenshot saved as screenshot.png\")\n",
        "\n",
        "        # Extract job details using selectors (adjust selectors as needed)\n",
        "        try:\n",
        "            job_title = await page.inner_text('h1.top-card-layout__title')\n",
        "            company = await page.inner_text('a.topcard__org-name-link')\n",
        "            location = await page.inner_text('span.topcard__flavor--bullet')\n",
        "            description = await page.inner_text('div.show-more-less-html__markup')\n",
        "\n",
        "            # Prepare job details for saving\n",
        "            job_details = (\n",
        "                f\"Job Title    : {job_title}\\n\"\n",
        "                f\"Company      : {company}\\n\"\n",
        "                f\"Location     : {location}\\n\"\n",
        "                f\"Description  : {description}\\n\"\n",
        "            )\n",
        "\n",
        "            # Save job details to a text file\n",
        "            output_file = \"job_details.txt\"\n",
        "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(job_details)\n",
        "\n",
        "            print(f\"Job details saved to {output_file}\")\n",
        "            return output_file\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while scraping: {e}\")\n",
        "            return None\n",
        "\n",
        "        finally:\n",
        "            # Close the browser\n",
        "            await browser.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "Pc4yPKy6p4lu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize combined_output\n",
        "combined_output = \"\"\n",
        "\n",
        "# Process Experience HTML\n",
        "print(\"Processing Experience HTML...\")\n",
        "experience_output = process_experience_html(experience_html)\n",
        "combined_output += experience_output\n",
        "\n",
        "# Process Education HTML\n",
        "print(\"Processing Education HTML...\")\n",
        "education_output = process_education_html(education_html)\n",
        "combined_output += education_output\n",
        "\n",
        "# Process Skills HTML\n",
        "print(\"Processing Skills HTML...\")\n",
        "skills_output = process_skills_html(skills_html)\n",
        "combined_output += skills_output\n",
        "\n",
        "# Save the combined output to a single file\n",
        "final_output_file = \"profile_data.txt\"\n",
        "with open(final_output_file, \"w\") as file:\n",
        "    file.write(combined_output)\n",
        "\n",
        "print(\"Combined profile data saved to profile_data.txt\")\n",
        "files.download(final_output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "1BjJNv98WTTg",
        "outputId": "6de3e992-55a8-43e5-cda5-c43a289a7d5f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Experience HTML...\n",
            "Processing Education HTML...\n",
            "Processing Skills HTML...\n",
            "Combined profile data saved to profile_data.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_72930152-164d-420a-8dbc-7c49c731f33b\", \"profile_data.txt\", 1131)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### moving to job data\n",
        "\n",
        "\n",
        "# Run the scraping function\n",
        "output_file = await scrape_job_posting(job_url)\n",
        "\n",
        "# Allow user to download the file\n",
        "if output_file:\n",
        "    from google.colab import files\n",
        "    files.download(output_file)\n"
      ],
      "metadata": {
        "id": "Y6jOi5zEtAbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
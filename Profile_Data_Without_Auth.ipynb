{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8OSJKIly9smDZgFSLBRqZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbehargithub/LinkedIn_Salary/blob/main/Profile_Data_Without_Auth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "from re import sub\n"
      ],
      "metadata": {
        "id": "QsUA4CBFdR9x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_experience_html(html_experience):\n",
        "    \"\"\"\n",
        "    Process the HTML file for the Experience section.\n",
        "    \"\"\"\n",
        "    soup_experience = BeautifulSoup(html_experience, \"html.parser\")\n",
        "    # Initialize the output variable to collect results\n",
        "    output = \"Experience Section:\\n\\n\"\n",
        "\n",
        "    # Locate the experience section in the HTML using its aria-label\n",
        "    experience_section = soup_experience.find(\"main\", {\"aria-label\": \"Experience\"})\n",
        "\n",
        "    # Find all job records within the experience section\n",
        "    records = experience_section.find_all(\"li\", class_=\"pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column\")\n",
        "\n",
        "    # Process each job record\n",
        "    for record in records:\n",
        "        # Check if the record contains sub-records (multiple roles in one company)\n",
        "        sub_records = record.find_all(\"li\", class_=\"pvs-list__paged-list-item pvs-list__item--one-column\")\n",
        "\n",
        "        # Handle a single position in one company\n",
        "        if len(sub_records) == 0:\n",
        "            # Extract job title\n",
        "            job_name_container = record.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\") or \\\n",
        "                                record.find(\"div\", class_=\"display-flex align-items-center mr1 t-bold\")\n",
        "            job_name = (\n",
        "                job_name_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "                if job_name_container else \"N/A\"\n",
        "            )\n",
        "\n",
        "            # Extract company name and job type\n",
        "            job_place_and_type_container = record.find(\"span\", class_=\"t-14 t-normal\")\n",
        "            if job_place_and_type_container:\n",
        "                place_and_type = job_place_and_type_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "                if \"路\" in place_and_type:\n",
        "                    company_name, job_type = [part.strip() for part in place_and_type.split(\"路\", 1)]\n",
        "                else:\n",
        "                    company_name, job_type = \"N/A\", place_and_type\n",
        "            else:\n",
        "                company_name, job_type = \"N/A\", \"N/A\"\n",
        "\n",
        "            # Extract job duration and location\n",
        "            job_info_container = record.find_all(\"span\", class_=\"t-14 t-normal t-black--light\")\n",
        "            info = [span.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) for span in job_info_container if span.find(\"span\", {\"aria-hidden\": \"true\"})]\n",
        "            job_duration = info[0] if len(info) > 0 else \"N/A\"\n",
        "            job_location = info[1] if len(info) > 1 else \"N/A\"\n",
        "\n",
        "            # Extract additional content and skills\n",
        "            additional_content_container = record.find_all(\"div\", class_=\"display-flex align-items-center t-14 t-normal t-black\")\n",
        "            additional_content_and_skills = [span.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) for span in additional_content_container if span.find(\"span\", {\"aria-hidden\": \"true\"})]\n",
        "            additional_content = additional_content_and_skills[0] if len(additional_content_and_skills) > 0 else \"N/A\"\n",
        "\n",
        "            skills = additional_content_and_skills[1] if len(additional_content_and_skills) > 1 else \"N/A\"\n",
        "            skills = skills.replace(\"Skills:\", \"\").strip()\n",
        "\n",
        "            # Append results to the output in a clean format\n",
        "            output += (\n",
        "                f\"Job Title     : {job_name}\\n\"\n",
        "                f\"Company       : {company_name}\\n\"\n",
        "                f\"Job Type      : {job_type}\\n\"\n",
        "                f\"Job Duration  : {job_duration}\\n\"\n",
        "                f\"Location      : {job_location}\\n\"\n",
        "                f\"Description   : {additional_content}\\n\"\n",
        "                f\"Skills        : {skills}\\n\"\n",
        "                f\"{'-' * 50}\\n\"\n",
        "            )\n",
        "        else:\n",
        "            # Handle multiple roles in the same company\n",
        "            title_container = record.find(\"div\", class_=\"display-flex flex-row justify-space-between\")\n",
        "            company_name_container = title_container.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\") or \\\n",
        "                                    title_container.find(\"div\", class_=\"display-flex align-items-center mr1 t-bold\")\n",
        "            company_name = (\n",
        "                company_name_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "                if company_name_container else \"N/A\"\n",
        "            )\n",
        "            duration_container = title_container.find(\"span\", class_=\"t-14 t-normal\")\n",
        "            duration = duration_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "\n",
        "            # Append company details to the output\n",
        "            output += (\n",
        "                f\"Company       : {company_name}\\n\"\n",
        "                f\"Duration      : {duration}\\n\"\n",
        "                f\"{'-' * 50}\\n\"\n",
        "            )\n",
        "\n",
        "            # Process each sub-record (job role)\n",
        "            for sub_record in sub_records:\n",
        "                # Extract job title\n",
        "                job_name_container = sub_record.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\") or \\\n",
        "                                    sub_record.find(\"div\", class_=\"display-flex align-items-center mr1 t-bold\")\n",
        "                job_name = (\n",
        "                    job_name_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "                    if job_name_container else \"N/A\"\n",
        "                )\n",
        "\n",
        "                # Extract company name and job type\n",
        "                job_place_and_type_container = sub_record.find(\"span\", class_=\"t-14 t-normal\")\n",
        "                if job_place_and_type_container:\n",
        "                    place_and_type = job_place_and_type_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True)\n",
        "                    if \"路\" in place_and_type:\n",
        "                        company_name, job_type = [part.strip() for part in place_and_type.split(\"路\", 1)]\n",
        "                    else:\n",
        "                        company_name, job_type = \"N/A\", place_and_type\n",
        "                else:\n",
        "                    company_name, job_type = \"N/A\", \"N/A\"\n",
        "\n",
        "                # Extract job duration and location\n",
        "                job_info_container = sub_record.find_all(\"span\", class_=\"t-14 t-normal t-black--light\")\n",
        "                info = [span.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) for span in job_info_container if span.find(\"span\", {\"aria-hidden\": \"true\"})]\n",
        "                job_duration = info[0] if len(info) > 0 else \"N/A\"\n",
        "                job_location = info[1] if len(info) > 1 else \"N/A\"\n",
        "\n",
        "                # Extract additional content and skills\n",
        "                additional_content_container = sub_record.find_all(\"div\", class_=\"display-flex align-items-center t-14 t-normal t-black\")\n",
        "                if len(additional_content_container) == 1:\n",
        "                  if \"Skills:\" in additional_content_container[0].get_text(strip=True):\n",
        "                    additional_content_and_skills = [span.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) for span in additional_content_container]\n",
        "                    skills = additional_content_and_skills[0]\n",
        "                    skills = skills.replace(\"Skills:\", \"\").strip()\n",
        "                else:\n",
        "\n",
        "                    additional_content_and_skills = [span.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) for span in additional_content_container if span.find(\"span\", {\"aria-hidden\": \"true\"})]\n",
        "                    additional_content = additional_content_and_skills[0] if len(additional_content_and_skills) > 0 else \"N/A\"\n",
        "\n",
        "                    skills = additional_content_and_skills[1] if len(additional_content_and_skills) > 1 else \"N/A\"\n",
        "                    skills = skills.replace(\"Skills:\", \"\").strip()\n",
        "\n",
        "                # Append job role details to the output in a clean format\n",
        "                output += (\n",
        "                    f\"  Job Title    : {job_name}\\n\"\n",
        "                    f\"  Job Type     : {job_type}\\n\"\n",
        "                    f\"  Job Duration : {job_duration}\\n\"\n",
        "                    f\"  Location     : {job_location}\\n\"\n",
        "                    f\"  Description  : {additional_content}\\n\"\n",
        "                    f\"  Skills       : {skills}\\n\"\n",
        "                    f\"  {'-' * 50}\\n\"\n",
        "                )\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "Wdzv9a_idR7V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_education_html(html_education):\n",
        "    \"\"\"\n",
        "    Process the HTML file for the Education section.\n",
        "    \"\"\"\n",
        "    soup_education = BeautifulSoup(html_education, \"html.parser\")\n",
        "\n",
        "    output = \"Education Section:\\n\\n\"\n",
        "\n",
        "\n",
        "    # Locate the education section in the HTML\n",
        "    education_section = soup_education.find(\"main\", {\"aria-label\": \"Education\"})\n",
        "\n",
        "    # Find all education records within the section\n",
        "    education_records = education_section.find_all(\"div\", {\"data-view-name\": \"profile-component-entity\"})\n",
        "\n",
        "    # Process each education record\n",
        "    for record in education_records:\n",
        "        # Extract institution name\n",
        "        institution_container = record.find(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\")\n",
        "        institution_name = institution_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) if institution_container else \"N/A\"\n",
        "        output += f\"Institution     : {institution_name}\\n\"\n",
        "\n",
        "        # Extract date range\n",
        "        date_container = record.find(\"span\", class_=\"pvs-entity__caption-wrapper\")\n",
        "        date_range = date_container.get_text(strip=True) if date_container else \"N/A\"\n",
        "        output += f\"Date Range      : {date_range}\\n\"\n",
        "\n",
        "        # Extract additional description (e.g., degree or field of study)\n",
        "        description_container = record.find(\"span\", class_=\"t-14 t-normal\")\n",
        "        description_text = description_container.find(\"span\", {\"aria-hidden\": \"true\"}).get_text(strip=True) if description_container else \"N/A\"\n",
        "        output += f\"Description     : {description_text}\\n\"\n",
        "\n",
        "        # Extract skills (if available)\n",
        "        skills_container = record.find(\"div\", class_=\"display-flex align-items-center t-14 t-normal t-black\")\n",
        "        skills = []\n",
        "        if skills_container:\n",
        "            skills_span = skills_container.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "            if skills_span:\n",
        "                skills_text = skills_span.get_text(strip=True)\n",
        "                if \"Skills:\" in skills_text:\n",
        "                    skills_text = skills_text.replace(\"Skills:\", \"\").strip()\n",
        "                skills = [skill.strip() for skill in skills_text.split(\"路\")]\n",
        "        output += f\"Skills          : {', '.join(skills) if skills else 'N/A'}\\n\"\n",
        "\n",
        "        # Extract additional text (e.g., detailed explanations)\n",
        "        additional_text_container = record.find(\"div\", class_=\"inline-show-more-text--is-collapsed\")\n",
        "        additional_text = \"\"\n",
        "        if additional_text_container:\n",
        "            additional_span = additional_text_container.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "            if additional_span:\n",
        "                additional_text = additional_span.get_text(\" \", strip=True)\n",
        "        output += f\"Additional Text : {additional_text if additional_text else 'N/A'}\\n\"\n",
        "\n",
        "        # Append a separator for readability\n",
        "        output += \"-\" * 50 + \"\\n\"\n",
        "\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "Zza3VzrVdR4g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_skills_html(html_skills):\n",
        "    \"\"\"\n",
        "    Process the HTML file for the Education section.\n",
        "    \"\"\"\n",
        "    soup_skills = BeautifulSoup(html_skills, \"html.parser\")\n",
        "\n",
        "    output = \"Skills Section:\\n\\n\"\n",
        "\n",
        "    # Find all <a> tags with data-field=\"skill_page_skill_topic\"\n",
        "    skill_links = soup_skills.find_all(\"a\", {\"data-field\": \"skill_page_skill_topic\"})\n",
        "\n",
        "    # Extract skills\n",
        "    skills = []\n",
        "    for link in skill_links:\n",
        "        # Find the <span> with aria-hidden=\"true\" inside the link\n",
        "        skill_span = link.find(\"span\", {\"aria-hidden\": \"true\"})\n",
        "        if skill_span:\n",
        "            skill_text = skill_span.get_text(strip=True)\n",
        "            skills.append(skill_text)\n",
        "\n",
        "    unique_skills = sorted(set(skills))\n",
        "\n",
        "    output += f\"Unique skills: {', '.join(unique_skills)}\\n\"\n",
        "    output += \"-\" * 50 + \"\\n\"\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "R56gEMCcdR1_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_and_process(section_name, process_function):\n",
        "    \"\"\"\n",
        "    Helper function to upload a file, process it, and append the results to combined_output.\n",
        "    \"\"\"\n",
        "    print(f\"Please upload the {section_name} HTML file:\")\n",
        "    uploaded_files = files.upload()\n",
        "    file_name, content = next(iter(uploaded_files.items()))\n",
        "\n",
        "    print(f\"Processing {section_name} file: {file_name}\\n\")\n",
        "    output = process_function(content)\n",
        "\n",
        "    # Append the section output to the combined output\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "-byMpBIxgMqG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install playwright\n",
        "!playwright install"
      ],
      "metadata": {
        "id": "VdMzZTbIqayx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from playwright.async_api import async_playwright\n",
        "import asyncio\n",
        "\n",
        "async def scrape_job_posting(job_url):\n",
        "    \"\"\"\n",
        "    Scrape job posting details from a LinkedIn job URL and save to a file.\n",
        "    \"\"\"\n",
        "    async with async_playwright() as p:\n",
        "        # Launch browser in headless mode\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        context = await browser.new_context(user_agent=\"Mozilla/5.0\")\n",
        "        page = await context.new_page()\n",
        "\n",
        "        # Navigate to the provided job URL\n",
        "        print(f\"Navigating to {job_url}...\")\n",
        "        await page.goto(job_url)\n",
        "        await asyncio.sleep(5)  # Wait for the page to fully load\n",
        "\n",
        "        # Save the page's HTML content for debugging purposes\n",
        "        # html = await page.content()\n",
        "        # with open(\"page_debug.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "        #     f.write(html)\n",
        "        # print(\"Saved page content to page_debug.html\")\n",
        "\n",
        "        # Take a screenshot of the page for verification\n",
        "        # await page.screenshot(path=\"screenshot.png\", full_page=True)\n",
        "        # print(\"Screenshot saved as screenshot.png\")\n",
        "\n",
        "        # Extract job details using selectors (adjust selectors as needed)\n",
        "        try:\n",
        "            job_title = await page.inner_text('h1.top-card-layout__title')\n",
        "            company = await page.inner_text('a.topcard__org-name-link')\n",
        "            location = await page.inner_text('span.topcard__flavor--bullet')\n",
        "            description = await page.inner_text('div.show-more-less-html__markup')\n",
        "\n",
        "            # Prepare job details for saving\n",
        "            job_details = (\n",
        "                f\"Job Title    : {job_title}\\n\"\n",
        "                f\"Company      : {company}\\n\"\n",
        "                f\"Location     : {location}\\n\"\n",
        "                f\"Description  : {description}\\n\"\n",
        "            )\n",
        "\n",
        "            # Save job details to a text file\n",
        "            output_file = \"job_details.txt\"\n",
        "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(job_details)\n",
        "\n",
        "            print(f\"Job details saved to {output_file}\")\n",
        "            return output_file\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while scraping: {e}\")\n",
        "            return None\n",
        "\n",
        "        finally:\n",
        "            # Close the browser\n",
        "            await browser.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "Pc4yPKy6p4lu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize combined_output\n",
        "combined_output = \"\"\n",
        "\n",
        "# Process Experience HTML and update combined_output\n",
        "experience_output = upload_and_process(\"Experience\", process_experience_html)\n",
        "\n",
        "# Process Education HTML and update combined_output\n",
        "education_output = upload_and_process(\"Education\", process_education_html)\n",
        "\n",
        "# Process Skills HTML and update combined_output\n",
        "skills_output = upload_and_process(\"Skills\", process_skills_html)\n",
        "\n",
        "combined_output += experience_output\n",
        "combined_output += education_output\n",
        "combined_output += skills_output\n",
        "\n",
        "# Save the combined output to a single file\n",
        "final_output_file = \"_profile_data.txt\"\n",
        "with open(final_output_file, \"w\") as file:\n",
        "    file.write(combined_output)\n",
        "\n",
        "# Provide the combined output file for download\n",
        "files.download(final_output_file)\n",
        "\n"
      ],
      "metadata": {
        "id": "1BjJNv98WTTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### moving to job data\n",
        "\n",
        "# Request the URL from the user\n",
        "job_url = input(\"Please enter the LinkedIn job URL: \").strip()\n",
        "\n",
        "# Run the scraping function\n",
        "output_file = await scrape_job_posting(job_url)\n",
        "\n",
        "# Allow user to download the file\n",
        "if output_file:\n",
        "    from google.colab import files\n",
        "    files.download(output_file)\n"
      ],
      "metadata": {
        "id": "Y6jOi5zEtAbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}